<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<title>GopherCon EU 2025</title>

	<link rel="stylesheet" href="../lib/reveal.js-2025-01-30/dist/reset.css">
	<link rel="stylesheet" href="../lib/reveal.js-2025-01-30/dist/reveal.css">
	<link rel="stylesheet" href="../lib/reveal.js-2025-01-30/dist/theme/black.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="../lib/reveal.js-2025-01-30/plugin/highlight/monokai.css">

	<script src="https://kit.fontawesome.com/83ed4ad257.js" crossorigin="anonymous" defer></script>

	<style>
		.reveal pre code {
			-moz-tab-size: 4;
			tab-size: 4;
			max-height: initial;
		}

		.reveal h1,
		.reveal h2,
		.reveal h3 {
			text-transform: initial;
		}
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h2>Ayke van Laethem</h2>
				<p><em>Implementing parallelism</em></p>
				<p style="font-size: 80%"><em>How we added threading and multicore support to TinyGo</em></p>
				<p>
					<i class="fa-brands fa-mastodon"></i> <a href="https://hachyderm.io/aykevl">@ayke@hachyderm.io</a><br />
					<i class="fa-brands fa-telegram"></i> <a href="https://telegram.me/aykevl">@aykevl</a><br />
					<i class="fa-brands fa-github"></i> <a href="https://github.com/aykevl">@aykevl</a>
				</p>
				<aside class="notes" data-markdown>
					thank you
				</aside>
			</section>

			<section>
				<h1>TL;DR</h1>
				<ul>
					<li>Multicore support on Linux (threads)</li>
					<li>Multicore support on baremetal (RP2040, custom scheduler)</li>
				</ul>
				<aside class="notes" data-markdown>
					(slide)

					Here to talk about how I did that.
				</aside>
			</section>

			<section>
				<h2>Concurrency != parallelism</h2>
				<aside class="notes" data-markdown>
					Go: built into language

					Until Go 1.5 single threaded by default

					TinyGo: not needed, MCUs single core

					---

					This has now changed
				</aside>
			</section>
			<section>
				<h2>Why now in TinyGo?</h2>
				<ul>
					<li>New chips (RP2040)</li>
					<li>Linux (example: u-root)</li>
					<li>WebAssembly (stack switching is painful)</li>
				</ul>
				<aside class="notes" data-markdown>
					baremetal: RP2040 did not exist when I started TinyGo

					Linux: used by u-root (busybox like system)

					WebAssembly: better than Asyncify  
					-> unwind & rewind the stack on goroutine switch  
					-> use Web Workers instead (also perf)
				</aside>
			</section>
			<section>
				<h2>1:1 threading?</h2>
				<img src="plot-launch-switch.png" style="height: 40vh">

				<p style="font-size: 0.5em">Source:<br><a
						href="https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/">https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/</a>
				</p>

				<aside class="notes" data-markdown>
					different!

					goroutine = OS thread

					con:
					- RAM (8k, rest virtual as-needed)
					- slower: start goroutine & context switch

					pro: simplicity
					- direct CGo calls (no switch to C)
					- direct syscalls like read/write (epoll for I/O)
					- preemptive scheduling (goroutines don't hang)
					- -> much simpler/smaller implementation

					---

					Lots changes needed to make this work
				</aside>
			</section>
			<section>
				<h2>What needs to change?</h2>
				<ul>
					<li>scheduler</li>
					<li>garbage collector</li>
					<li><code>chan</code>, <code>select</code></li>
					<li>package <code>sync</code></li>
					<li>package <code>sync/atomic</code></li>
					<li>misc: <code>println</code>, <code>runtime.NumCPU</code>, etc</li>
				</ul>
				<aside class="notes" data-markdown>
					scheduler: user space -> thread

					GC: pause other threads while scanning

					sync: obviously

					sync/atomic: built into LLVM

					println: lock stdout to avoid interleaving lines
				</aside>
			</section>
			<section>
				<h2>Futex!</h2>
				<p>What even is a futex?</p>
				<aside class="notes" data-markdown>
					to simplify impl of synchronization primitives...

					"Fast userspace mutex"
					syscall: not fast, not userspace

					Building block of concurrency primitives.
					-> to build mutex, semaphore, WaitGroup, channels

					Fast (userspace) if uncontended, fallback if contended
				</aside>
			</section>
			<section>
				<h2>Futex API</h2>
				<ul style="font-size: 70%">
					<li><code>wait(address *atomic.Uint32, expected uint32)</code></li>
					<li><code>wakeOne(address *atomic.Uint32)</code></li>
					<li><code>wakeAll(address *atomic.Uint32)</code></li>
				</ul>

				<pre><code class="language-go" data-trim style="font-size: 90%; line-height: 1.2;">
						// In the kernel:
						var waitingThreads = make(map[*atomic.Uint32][]*OSThread)

						func wait(address *atomic.Uint32, expected uint32) {
							// do atomically:
							if address.Load() == expected {
								waitingThreads[address] = append(waitingThreads[address],
								                                 currentThread())
								// and now wait until woken
							}
						}
					</code></pre>
				<aside class="notes" data-markdown>
					2 or 3 calls depending on how you count

					based on atomic instructions

					OS internal hashmap
					address used as key

					Note: not waiting for value change!

					Every OS different...
				</aside>
			</section>

			<!--<section>
					<h2>Futex pseudocode</h2>

					<pre><code class="language-go" data-trim>
						type Futex struct {
							atomic.Uint32
						}

						func (f *Futex) Wait(expected uint32) {
							if f.Load() == expected {
								// blocks here until woken by Wake()
							}
						}

						func (f *Futex) Wake() {
							// wakes 
						}
					</code></pre>
				</section>-->


			<section>
				<table style="font-size: 80%">
					<thead>
						<tr>
							<th>Platform</th>
							<th>API</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>Linux</td>
							<td>see <code>futex(2)</code></td>
						</tr>
						<tr>
							<td>MacOS</td>
							<td><code>__ulock_wait2</code><br><code>__ulock_wake</code></coce>
							</td>
						</tr>
						<tr>
							<td>Windows</td>
							<td><code>WaitOnAddress</code><br><code>WakeByAddressSingle</code><br><code>WakeByAddressAll</code></td>
						</tr>
						<tr>
							<td>WebAssembly</td>
							<td><code>memory.atomic.wait</code><br><code>memory.atomic.notify</code></td>
						</tr>
					</tbody>
				</table>
				<p style="font-size: 80%">More information:<br><a
						href="https://outerproduct.net/futex-dictionary.html">https://outerproduct.net/futex-dictionary.html</a></p>
				<aside class="notes" data-markdown>
					Linux: overloaded syscall

					MacOS: used inside C++ std lib

					WebAssembly: subset of all OSes

					---

					In TinyGo wrapped nice API
				</aside>
			</section>

			<section>
				<h2>Wrapped futex (TinyGo)</h2>
				<pre><code class="language-go" data-trim>
						type Futex struct {
							atomic.Uint32
						}

						func (f *Futex) Wait(expected uint32) {
							wait(&f.Uint32, expected)
						}

						func (f *Futex) Wake() {
							wakeOne(&f.Uint32)
						}

						func (f *Futex) WakeAll() {
							wakeAll(&f.Uint32)
						}
					</code></pre>
				<aside class="notes" data-markdown>
					Embed atomic uint32
					-> superset of atomic variable

					Same API as before
				</aside>
			</section>

			<section>
				<h2>Baremetal futex?</h2>
				<pre><code class="language-go" data-trim style="font-size: 85%; line-height: 1.2">
						type Futex struct {
							atomic.Uint32

							waiters Stack // linked list of waiting goroutines
						}

						func (f *Futex) Wait(expected uint32) {
							spinlockTake()
							if f.Load() == cmp {
								f.waiters.Push(currentGoroutine())
								spinlockRelease()
								Pause()
							} else {
								spinlockRelease()
							}
						}

						func (f *Futex) Wake() {
							spinlockTake()
							if t := f.waiters.Pop(); t != nil {
								scheduleGoroutine(t)
							}
							spinlockRelease()
						}
						
					</code></pre>
				<aside class="notes" data-markdown>
					Baremetal: same Go API

					This time, TinyGo *is* the OS

					Keep atomic uint32, add list of waiting tasks

					spinlock = HW spinlock

					(explanation of code)
				</aside>
			</section>

			<section>
				<p><code>sync.WaitGroup</code></p>
				<pre><code class="language-go" data-trim>
						type WaitGroup struct {
							futex Futex
						}

						func (wg *WaitGroup) Add(delta int) {
							if wg.futex.Add(uint32(delta)) == 0 {
								wg.futex.WakeAll()
							}
						}

						func (wg *WaitGroup) Wait() {
							for {
								counter := wg.futex.Load()
								if counter == 0 { break }
								wg.futex.Wait(counter)
							}
						}

						func (wg *WaitGroup) Done() {
							wg.Add(-1)
						}
					</code></pre>
				<aside class="notes" data-markdown>
					- skipped overflow checks
					- Go is different

					standard methods: Add, Wait, Done
					Done wrapper for Add

					Add: ...
					Wait: waits for value to become zero
					-> better than spinlock

					Note: WakeAll called only when 0, but spurious wakeups
				</aside>
			</section>

			<section>
				<h2>Channels</h2>

				<pre><code class="language-go" data-trim data-line-numbers="1,2,10-12,14">
						// The runtime implementation of the Go 'chan' type.
						type channel struct {
							closed       bool
							selectLocked bool
							elementSize  uintptr
							bufCap       uintptr // 'cap'
							bufLen       uintptr // 'len'
							bufHead      uintptr
							bufTail      uintptr
							senders      chanQueue
							receivers    chanQueue
							lock         task.PMutex
							buf          unsafe.Pointer
						}
					</code></pre>
				<aside class="notes" data-markdown>
					normal: mutex + linked list

					Example: send
					* lock
					* if receiver: proceed
					* if buffer space: store
					* else:
					* add to linked list of senders
					* pause until woken

					---
					Reeelatively straightforward. Select more complex
				</aside>
			</section>

			<section>
				<h2><code>select</code></h2>

				<pre><code class="language-go" data-trim="">
						var chan1 = make(chan int)
						var chan2 = make(chan int)

						func foo() {
							select {
								case <-chan1:
								case chan2 <- 1: // deadlock!
							}
						}

						func bar() {
							select {
								case chan2 <- 1:
								case <-chan1: // deadlock!
							}
						}
					</code></pre>
				<aside class="notes" data-markdown>
					need to lock every channel
					* check status
					* add to senders/receivers linked list

					can lead to deadlock

					solution: global mutex
				</aside>
			</section>

			<section>
				<h2>RP2040</h2>
				<table>
					<tr>
						<th>Before</th>
						<th>After</th>
					</tr>
					<tr>
						<td>
							<video autoplay width="300vw" loop src="mandelbrot-before.mp4"></video>
						</td>
						<td>
							<video autoplay width="300vw" loop src="mandelbrot-after.mp4"></video>
						</td>
					</tr>
				</table>
				<aside class="notes" data-markdown>
					See:
					Mandelbrot renderer on the Gopher Badge
					Parallel makes it 30% faster

					Also embedded:
					run scheduler on both cores

					demo?
				</aside>
			</section>

			<section>
				<h2>Baremetal multicore</h2>
				<ul>
					<li>Debug in QEMU!</li>
					<li>Scheduler: one scheduler per core</li>
					<li>GC: interrupt every other core (using software interrupt)</li>
					<li><code>time.Sleep</code>: one core sleeps, others wait until a new task arrives</li>
				</ul>
				<aside class="notes" data-markdown>
					* RISC-V first!  
					  QEMU VirtIO
					* RP2040: just hardware specific bits
				</aside>
			</section>

			<section>
				<h2>Future work</h2>

				<ul>
					<li>MacOS support (almost done)</li>
					<li>WebAssembly threads support</li>
					<li>ESP32 support (maybe)</li>
					<li>Performance improvements</li>
				</ul>
				<aside class="notes" data-markdown>
					Where we are today.

					* Linux: done
					* MacOS: almost done
					* baremetal: works for the RP2040
				</aside>
			</section>

			<section>
				<h2>Questions?</h2>
				Slides:<br />
				<a href="https://aykevl.nl/talks/2025-06-17-gopherconeu/">https://aykevl.nl/talks/2025-06-17-gopherconeu/</a>
				<p>
					How to find me:<br>
					<i class="fa-brands fa-mastodon"></i> <a href="https://hachyderm.io/aykevl">@ayke@hachyderm.io</a><br />
					<i class="fa-brands fa-telegram"></i> <a href="https://telegram.me/aykevl">@aykevl</a><br />
					<i class="fa-brands fa-github"></i> <a href="https://github.com/aykevl">@aykevl</a>
				</p>
			</section>

			<section>
				<img src="rust-atomics-and-locks.jpg" style="height: 60vh"/>
			</section>
		</div>
	</div>

	<script src="../lib/reveal.js-2025-01-30/dist/reveal.js"></script>
	<script src="../lib/reveal.js-2025-01-30/plugin/notes/notes.js"></script>
	<script src="../lib/reveal.js-2025-01-30/plugin/markdown/markdown.js"></script>
	<script src="../lib/reveal.js-2025-01-30/plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
		});
	</script>
</body>

</html>
